{
  "name": "llama-chat-frontend",
  "version": "0.1.0",
  "type": "module",
  "scripts": {
    "ensure-cmake": "cargo build --manifest-path tools/ensure-cmake/Cargo.toml --release",
    "cargo": "cargo run --manifest-path tools/ensure-cmake/Cargo.toml --release --quiet -- cargo",
    "dev:frontend": "vite --host --port 4000",
    "dev": "npm run ensure-cmake && concurrently \"vite --host --port 4000\" \"npm run cargo -- build --bin llama_chat_web && npm run cargo -- run --bin llama_chat_web\"",
    "dev:auto": "node scripts/detect-and-run.js web",
    "dev:auto:desktop": "node scripts/detect-and-run.js desktop",
    "dev:web": "npm run ensure-cmake && concurrently \"vite --host --port 4000\" \"npm run cargo -- build --bin llama_chat_web && npm run cargo -- run --bin llama_chat_web\"",
    "dev:cuda": "npm run ensure-cmake && concurrently \"vite --host --port 4000\" \"npm run cargo -- build --features cuda --bin llama_chat_web && npm run cargo -- run --features cuda --bin llama_chat_web\"",
    "dev:metal": "npm run ensure-cmake && concurrently \"vite --host --port 4000\" \"npm run cargo -- build --features metal --bin llama_chat_web && npm run cargo -- run --features metal --bin llama_chat_web\"",
    "build": "tsc && vite build",
    "build:rust": "npm run cargo -- build --bin llama_chat_web",
    "build:cuda": "npm run cargo -- build --features cuda --bin llama_chat_web",
    "build:metal": "npm run cargo -- build --features metal --bin llama_chat_web",
    "tauri:dev": "npm run cargo -- tauri dev",
    "tauri:dev:cuda": "npm run cargo -- tauri dev --features cuda",
    "tauri:dev:metal": "npm run cargo -- tauri dev --features metal",
    "tauri:build": "npm run cargo -- tauri build",
    "tauri:build:cuda": "npm run cargo -- tauri build --features cuda",
    "tauri:build:metal": "npm run cargo -- tauri build --features metal",
    "preview": "vite preview",
    "typecheck": "tsc --noEmit",
    "lint": "eslint --max-warnings 0 \"src/**/*.{ts,tsx}\"",
    "lint:size": "node scripts/check-file-sizes.js",
    "test": "playwright test",
    "test:e2e": "playwright test",
    "test:ui": "playwright test --ui",
    "test:headed": "playwright test --headed",
    "test:debug": "playwright test --debug",
    "test:docker": "docker compose down && TEST_MODE=true docker compose up -d && sleep 5 && playwright test && docker compose down && docker compose up -d"
  },
  "dependencies": {
    "@radix-ui/react-dialog": "^1.1.15",
    "@radix-ui/react-icons": "^1.3.2",
    "@radix-ui/react-select": "^2.2.6",
    "@radix-ui/react-slider": "^1.3.6",
    "@radix-ui/react-slot": "^1.2.3",
    "@tailwindcss/typography": "^0.5.19",
    "@tauri-apps/api": "^2.0.0",
    "@tauri-apps/plugin-clipboard-manager": "^2.3.2",
    "@tauri-apps/plugin-dialog": "^2.4.0",
    "@tauri-apps/plugin-notification": "^2.3.3",
    "@tauri-apps/plugin-opener": "^2.5.3",
    "@tauri-apps/plugin-shell": "^2.0.0",
    "@tauri-apps/plugin-window-state": "^2.4.1",
    "@types/react-syntax-highlighter": "^15.5.13",
    "autoprefixer": "^10.4.21",
    "class-variance-authority": "^0.7.1",
    "clsx": "^2.1.1",
    "express": "^5.1.0",
    "highlight.js": "^11.11.1",
    "lucide-react": "^0.544.0",
    "postcss": "^8.5.6",
    "react": "^18.2.0",
    "react-dom": "^18.2.0",
    "react-hot-toast": "^2.6.0",
    "react-markdown": "^10.1.0",
    "react-syntax-highlighter": "^16.1.0",
    "rehype-highlight": "^7.0.2",
    "remark-gfm": "^4.0.1",
    "tailwind-merge": "^3.3.1"
  },
  "devDependencies": {
    "@playwright/test": "^1.48.0",
    "@types/react": "^18.2.66",
    "@types/react-dom": "^18.2.22",
    "@typescript-eslint/eslint-plugin": "^6.21.0",
    "@typescript-eslint/parser": "^6.21.0",
    "@vitejs/plugin-react": "^4.2.1",
    "concurrently": "^8.2.2",
    "eslint": "^8.57.0",
    "eslint-plugin-react": "^7.33.2",
    "eslint-plugin-react-hooks": "^4.6.0",
    "tailwindcss": "3",
    "tw-animate-css": "^1.4.0",
    "typescript": "^5.2.2",
    "vite": "^5.2.0",
    "vite-plugin-checker": "^0.8.0"
  },
  "description": "A modern AI chat application built with Tauri, Rust, and llama-cpp-2. Features a beautiful UI with integrated shell command execution capabilities. Available as both a native desktop app and web application.",
  "main": "postcss.config.js",
  "directories": {
    "test": "tests"
  },
  "repository": {
    "type": "git",
    "url": "git+https://github.com/AgustinJimenez/llama_cpp_rs_chat.git"
  },
  "keywords": [],
  "author": "",
  "license": "ISC",
  "bugs": {
    "url": "https://github.com/AgustinJimenez/llama_cpp_rs_chat/issues"
  },
  "homepage": "https://github.com/AgustinJimenez/llama_cpp_rs_chat#readme"
}
