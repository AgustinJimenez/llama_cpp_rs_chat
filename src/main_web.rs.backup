// Simple web server version of LLaMA Chat (without Tauri)
mod web;  // Declare web module for model capabilities and utilities

// Import all types and functions from web modules
use web::*;

use std::net::SocketAddr;
use std::convert::Infallible;
use std::sync::{Arc, Mutex};
use std::fs;
use std::time::SystemTime;
use serde::Deserialize;
use serde_json;

// Helper function to get current timestamp for logging
fn timestamp_now() -> String {
    let now = SystemTime::now()
        .duration_since(SystemTime::UNIX_EPOCH)
        .unwrap();
    let secs = now.as_secs();
    let millis = now.subsec_millis();
    let hours = (secs / 3600) % 24;
    let minutes = (secs / 60) % 60;
    let seconds = secs % 60;
    format!("{:02}:{:02}:{:02}.{:03}", hours, minutes, seconds, millis)
}
use gguf_llms::{GgufHeader, GgufReader, Value};
use std::io::BufReader;
use tokio::sync::mpsc;
use hyper::body::Bytes;

// HTTP server using hyper
use hyper::service::{make_service_fn, service_fn};
use hyper::{Body, Method, Request, Response, Server, StatusCode};

// Note: All struct definitions (SamplerConfig, TokenData, ChatRequest, ChatResponse, etc.)
// and helper functions (load_config, add_to_model_history, get_model_status, etc.)
// are now imported from web modules (web::config, web::command, web::model_manager, etc.)


// All helper functions and struct definitions are imported from web modules

async fn handle_request(
    req: Request<Body>,
    llama_state: SharedLlamaState,
) -> std::result::Result<Response<Body>, Infallible> {
    handle_request_impl(req, Some(llama_state)).await
}

#[cfg(feature = "mock")]
async fn handle_request(
    req: Request<Body>,
) -> std::result::Result<Response<Body>, Infallible> {
    handle_request_impl(req, None).await
}

async fn handle_request_impl(
    req: Request<Body>,
    
    llama_state: Option<SharedLlamaState>,
    #[cfg(feature = "mock")]
    _llama_state: Option<()>,
) -> std::result::Result<Response<Body>, Infallible> {
    let response = match (req.method(), req.uri().path()) {
        (&Method::GET, "/health") => {
            Response::builder()
                .status(StatusCode::OK)
                .header("content-type", "application/json")
                .header("access-control-allow-origin", "*")
                .body(Body::from(r#"{"status":"ok","service":"llama-chat-web"}"#))
                .unwrap()
        }
        
        (&Method::POST, "/api/chat") => {
            // Parse request body
            let body_bytes = match hyper::body::to_bytes(req.into_body()).await {
                Ok(bytes) => bytes,
                Err(_) => {
                    return Ok(Response::builder()
                        .status(StatusCode::BAD_REQUEST)
                        .header("content-type", "application/json")
                        .header("access-control-allow-origin", "*")
                        .body(Body::from(r#"{"error":"Failed to read request body"}"#))
                        .unwrap());
                }
            };

            // Debug: log the received JSON
            if let Ok(body_str) = std::str::from_utf8(&body_bytes) {
                println!("Received request body: {}", body_str);
            }
            
            let chat_request: ChatRequest = match serde_json::from_slice(&body_bytes) {
                Ok(req) => req,
                Err(e) => {
                    println!("JSON parsing error: {}", e);
                    return Ok(Response::builder()
                        .status(StatusCode::BAD_REQUEST)
                        .header("content-type", "application/json")
                        .header("access-control-allow-origin", "*")
                        .body(Body::from(r#"{"error":"Invalid JSON format"}"#))
                        .unwrap());
                }
            };

            
            {
                // Check for test mode environment variable
                if std::env::var("TEST_MODE").unwrap_or_default() == "true" {
                    // Fast test response
                    let test_response = format!(
                        "Hello! This is a test response to your message: '{}'", 
                        chat_request.message
                    );
                    
                    let response = ChatResponse {
                        message: ChatMessage {
                            id: format!("{}", uuid::Uuid::new_v4()),
                            role: "assistant".to_string(),
                            content: test_response,
                            timestamp: std::time::SystemTime::now()
                                .duration_since(std::time::UNIX_EPOCH)
                                .unwrap_or_default()
                                .as_secs(),
                        },
                        conversation_id: chat_request.conversation_id.unwrap_or_else(|| format!("{}", uuid::Uuid::new_v4())),
                        tokens_used: None,
                        max_tokens: None,
                    };
                    
                    return Ok(Response::builder()
                        .status(StatusCode::OK)
                        .header("content-type", "application/json")
                        .header("access-control-allow-origin", "*")
                        .body(Body::from(serde_json::to_string(&response).unwrap()))
                        .unwrap());
                }
                
                // Create or load conversation logger
                let conversation_logger = if let Some(conversation_id) = &chat_request.conversation_id {
                    // Load existing conversation
                    match ConversationLogger::from_existing(conversation_id) {
                        Ok(logger) => Arc::new(Mutex::new(logger)),
                        Err(e) => {
                            return Ok(Response::builder()
                                .status(StatusCode::INTERNAL_SERVER_ERROR)
                                .header("content-type", "application/json")
                                .header("access-control-allow-origin", "*")
                                .body(Body::from(format!(r#"{{"error":"Failed to load conversation: {}"}}"#, e)))
                                .unwrap());
                        }
                    }
                } else {
                    // Create new conversation
                    let config = load_config();
                    let system_prompt = config.system_prompt.as_deref();

                    match ConversationLogger::new(system_prompt) {
                        Ok(logger) => Arc::new(Mutex::new(logger)),
                        Err(e) => {
                            return Ok(Response::builder()
                                .status(StatusCode::INTERNAL_SERVER_ERROR)
                                .header("content-type", "application/json")
                                .header("access-control-allow-origin", "*")
                                .body(Body::from(format!(r#"{{"error":"Failed to create conversation logger: {}"}}"#, e)))
                                .unwrap());
                        }
                    }
                };

                // Log user message immediately so WebSocket can pick it up
                {
                    let mut logger = conversation_logger.lock().unwrap();
                    logger.log_message("USER", &chat_request.message);
                }

                // Extract conversation ID immediately so we can return it
                let conversation_id = {
                    let logger = conversation_logger.lock().unwrap();
                    logger.get_conversation_id()
                };

                // Spawn generation in background - don't wait for it
                let message_clone = chat_request.message.clone();
                let conversation_logger_clone = conversation_logger.clone();
                let llama_state_clone = llama_state.clone();
                let conv_id_for_log = conversation_id.clone();
                eprintln!("[{}] [API_CHAT] Spawning background generation task for conversation: {}",
                    timestamp_now(), conv_id_for_log);
                // Use std::thread instead of tokio::spawn to avoid deadlocks
                // Generation is CPU-bound and doesn't need async runtime
                std::thread::spawn(move || {
                    eprintln!("[{}] [BACKGROUND_GEN] Thread started for: {}",
                        timestamp_now(), conv_id_for_log);
                    if let Some(state) = llama_state_clone {
                        eprintln!("[{}] [BACKGROUND_GEN] Calling generate_llama_response...",
                            timestamp_now());

                        // Clone state for use in panic handler (needs to outlive the closure)
                        let state_for_unload = state.clone();

                        // Wrap generation in panic handler to catch tokenization crashes
                        let panic_result = std::panic::catch_unwind(std::panic::AssertUnwindSafe(|| {
                            // Create a new tokio runtime for this thread
                            let rt = tokio::runtime::Runtime::new().unwrap();
                            rt.block_on(
                                generate_llama_response(&message_clone, state, conversation_logger_clone.clone(), None, true)
                            )
                        }));

                        match panic_result {
                            Ok(result) => {
                                // Generation completed or returned error
                                match result {
                                    Ok((_content, tokens, max_tok)) => {
                                        eprintln!("[{}] [BACKGROUND_GEN] Generation completed: {} tokens / {} max",
                                            timestamp_now(), tokens, max_tok);
                                    },
                                    Err(err) => {
                                        eprintln!("[{}] [BACKGROUND_GEN] Generation failed: {}",
                                            timestamp_now(), err);

                                        // Write error to conversation file so it's visible to user
                                        let mut logger = conversation_logger_clone.lock().unwrap();
                                        logger.log_message("SYSTEM", &format!("⚠️ Generation Error: {}", err));
                                        logger.log_message("SYSTEM", "The model encountered an error during generation. This may be due to:");
                                        logger.log_message("SYSTEM", "  - Complex output (large code blocks, JSON)");
                                        logger.log_message("SYSTEM", "  - Context size limitations");
                                        logger.log_message("SYSTEM", "  - Model tokenization issues");
                                        logger.log_message("SYSTEM", "Try simplifying your request or reducing context size.");
                                    }
                                }
                            },
                            Err(panic_err) => {
                                // Tokenization panic caught!
                                let panic_msg = if let Some(s) = panic_err.downcast_ref::<String>() {
                                    s.clone()
                                } else if let Some(s) = panic_err.downcast_ref::<&str>() {
                                    s.to_string()
                                } else {
                                    "Unknown panic".to_string()
                                };

                                eprintln!("[{}] [BACKGROUND_GEN] PANIC CAUGHT: {}",
                                    timestamp_now(), panic_msg);

                                // Write panic to conversation file
                                let mut logger = conversation_logger_clone.lock().unwrap();
                                logger.log_message("SYSTEM", "❌ Generation Crashed (Tokenization Panic)");
                                logger.log_message("SYSTEM", &format!("Panic message: {}", panic_msg));
                                logger.log_message("SYSTEM", "");
                                logger.log_message("SYSTEM", "This is a known issue with the llama-cpp-2 library.");
                                logger.log_message("SYSTEM", "The model has been automatically unloaded for safety.");
                                logger.log_message("SYSTEM", "");
                                logger.log_message("SYSTEM", "Please try:");
                                logger.log_message("SYSTEM", "  - Reload the model");
                                logger.log_message("SYSTEM", "  - Use a simpler, shorter prompt");
                                logger.log_message("SYSTEM", "  - Reduce context size in model settings");
                                logger.log_message("SYSTEM", "  - Avoid requests for large code blocks or complex JSON");
                                drop(logger); // Release lock before unloading model

                                // Automatically unload the model to prevent further crashes
                                eprintln!("[{}] [BACKGROUND_GEN] Auto-unloading model after panic...",
                                    timestamp_now());

                                // Unload model asynchronously
                                let rt = tokio::runtime::Runtime::new().unwrap();
                                match rt.block_on(unload_model(state_for_unload)) {
                                    Ok(_) => {
                                        eprintln!("[{}] [BACKGROUND_GEN] Model unloaded successfully",
                                            timestamp_now());
                                    }
                                    Err(e) => {
                                        eprintln!("[{}] [BACKGROUND_GEN] Failed to unload model: {}",
                                            timestamp_now(), e);
                                    }
                                }
                            }
                        }
                    } else {
                        eprintln!("[{}] [BACKGROUND_GEN] ERROR: llama_state is None!",
                            timestamp_now());
                    }
                });

                // Return immediately with conversation_id so frontend can connect WebSocket
                let chat_response = ChatResponse {
                    message: ChatMessage {
                        id: uuid::Uuid::new_v4().to_string(),
                        role: "assistant".to_string(),
                        content: "".to_string(), // Empty - real content comes via WebSocket
                        timestamp: std::time::SystemTime::now()
                            .duration_since(std::time::UNIX_EPOCH)
                            .unwrap_or_default()
                            .as_secs(),
                    },
                    conversation_id,
                    tokens_used: None,  // Will be updated via WebSocket
                    max_tokens: None,   // Will be updated via WebSocket
                };

                let response_json = match serde_json::to_string(&chat_response) {
                    Ok(json) => json,
                    Err(_) => r#"{"error":"Failed to serialize response"}"#.to_string(),
                };

                Response::builder()
                    .status(StatusCode::OK)
                    .header("content-type", "application/json")
                    .header("access-control-allow-origin", "*")
                    .header("access-control-allow-methods", "GET, POST, OPTIONS")
                    .header("access-control-allow-headers", "content-type")
                    .body(Body::from(response_json))
                    .unwrap()
            }

            #[cfg(feature = "mock")]
            {
                // Fallback mock response when using mock feature
                let mock_response = r#"{"message":{"id":"test","role":"assistant","content":"LLaMA integration not available (mock feature enabled)","timestamp":1234567890},"conversation_id":"test-conversation"}"#;
                Response::builder()
                    .status(StatusCode::OK)
                    .header("content-type", "application/json")
                    .header("access-control-allow-origin", "*")
                    .header("access-control-allow-methods", "GET, POST, OPTIONS")
                    .header("access-control-allow-headers", "content-type")
                    .body(Body::from(mock_response))
                    .unwrap()
            }
        }

        (&Method::POST, "/api/chat/stream") => {
            // Parse request body
            let body_bytes = match hyper::body::to_bytes(req.into_body()).await {
                Ok(bytes) => bytes,
                Err(_) => {
                    return Ok(Response::builder()
                        .status(StatusCode::BAD_REQUEST)
                        .header("content-type", "application/json")
                        .header("access-control-allow-origin", "*")
                        .body(Body::from(r#"{"error":"Failed to read request body"}"#))
                        .unwrap());
                }
            };

            let chat_request: ChatRequest = match serde_json::from_slice(&body_bytes) {
                Ok(req) => req,
                Err(e) => {
                    println!("JSON parsing error: {}", e);
                    return Ok(Response::builder()
                        .status(StatusCode::BAD_REQUEST)
                        .header("content-type", "application/json")
                        .header("access-control-allow-origin", "*")
                        .body(Body::from(r#"{"error":"Invalid JSON format"}"#))
                        .unwrap());
                }
            };

            
            {
                // Load configuration to get system prompt
                let config = load_config();
                let system_prompt = config.system_prompt.as_deref();

                // Create a new conversation logger for this chat session
                let conversation_logger = match ConversationLogger::new(system_prompt) {
                    Ok(logger) => Arc::new(Mutex::new(logger)),
                    Err(e) => {
                        return Ok(Response::builder()
                            .status(StatusCode::INTERNAL_SERVER_ERROR)
                            .header("content-type", "application/json")
                            .header("access-control-allow-origin", "*")
                            .body(Body::from(format!(r#"{{"error":"Failed to create conversation logger: {}"}}"#, e)))
                            .unwrap());
                    }
                };

                // Create channel for streaming tokens
                let (tx, mut rx) = mpsc::unbounded_channel::<TokenData>();

                // Spawn generation task
                let message = chat_request.message.clone();
                let state_clone = llama_state.clone();
                tokio::spawn(async move {
                    if let Some(state) = state_clone {
                        match generate_llama_response(&message, state, conversation_logger, Some(tx), false).await {
                            Ok((_content, tokens, max)) => {
                                println!("[DEBUG] Generation completed successfully: {} tokens used, {} max", tokens, max);
                            }
                            Err(e) => {
                                println!("[ERROR] Generation failed: {}", e);
                            }
                        }
                    } else {
                        println!("[ERROR] No LLaMA state available for generation");
                    }
                });

                // Use Body::channel for direct control over chunk sending
                let (mut sender, body) = Body::channel();

                // Spawn task to send tokens through the channel
                tokio::spawn(async move {
                    loop {
                        match rx.recv().await {
                            Some(token_data) => {
                                // Send TokenData as JSON
                                let json = serde_json::to_string(&token_data).unwrap_or_else(|_| r#"{"token":"","tokens_used":0,"max_tokens":0}"#.to_string());
                                let event = format!("data: {}\n\n", json);

                                // Send chunk immediately - this ensures no buffering
                                if sender.send_data(Bytes::from(event)).await.is_err() {
                                    // Client disconnected
                                    break;
                                }
                            }
                            None => {
                                // Channel closed, generation complete
                                break;
                            }
                        }
                    }
                    // Send done event
                    let _ = sender.send_data(Bytes::from("data: [DONE]\n\n")).await;
                });

                Response::builder()
                    .status(StatusCode::OK)
                    .header("content-type", "text/event-stream")
                    .header("cache-control", "no-cache")
                    .header("access-control-allow-origin", "*")
                    .header("connection", "keep-alive")
                    .header("x-accel-buffering", "no")  // Disable nginx buffering
                    .body(body)
                    .unwrap()
            }

            #[cfg(feature = "mock")]
            {
                Response::builder()
                    .status(StatusCode::OK)
                    .header("content-type", "application/json")
                    .header("access-control-allow-origin", "*")
                    .body(Body::from(r#"{"error":"Streaming not available (mock feature enabled)"}"#))
                    .unwrap()
            }
        }

        (&Method::GET, "/ws/chat/stream") => {

            // Check if the request wants to upgrade to WebSocket
            let upgrade_header = req.headers().get("upgrade")
                .and_then(|v| v.to_str().ok())
                .map(|v| v.to_lowercase());

            if upgrade_header.as_deref() != Some("websocket") {
                return Ok(Response::builder()
                    .status(StatusCode::BAD_REQUEST)
                    .header("content-type", "application/json")
                    .header("access-control-allow-origin", "*")
                    .body(Body::from(r#"{"error":"WebSocket upgrade required"}"#))
                    .unwrap());
            }

            // Extract the WebSocket key before moving req
            let key = req.headers()
                .get("sec-websocket-key")
                .and_then(|k| k.to_str().ok())
                .unwrap_or("")
                .to_string();

            // Calculate accept key using the WebSocket protocol
            let accept_key = {
                use sha1::{Digest, Sha1};
                use base64::{Engine as _, engine::general_purpose};

                let mut hasher = Sha1::new();
                hasher.update(key.as_bytes());
                hasher.update(b"258EAFA5-E914-47DA-95CA-C5AB0DC85B11");
                let hash = hasher.finalize();
                general_purpose::STANDARD.encode(hash)
            };

            // Clone state for the WebSocket handler
            let llama_state_ws = llama_state.clone();

            // Spawn WebSocket handler on the upgraded connection
            tokio::spawn(async move {
                match hyper::upgrade::on(req).await {
                    Ok(upgraded) => {
                        if let Err(e) = handle_websocket(upgraded, llama_state_ws).await {
                            println!("[WEBSOCKET ERROR] {}", e);
                        }
                    }
                    Err(e) => {
                        println!("[WEBSOCKET UPGRADE ERROR] {}", e);
                    }
                }
            });

            // Return 101 Switching Protocols response
            Response::builder()
                .status(StatusCode::SWITCHING_PROTOCOLS)
                .header("upgrade", "websocket")
                .header("connection", "upgrade")
                .header("sec-websocket-accept", accept_key)
                .body(Body::empty())
                .unwrap()
        }

        (&Method::GET, path) if path.starts_with("/ws/conversation/watch/") => {
            // Extract conversation ID from path
            let conversation_id = path.strip_prefix("/ws/conversation/watch/").unwrap_or("").to_string();
            eprintln!("[CONV-WATCH] WebSocket file watcher request for conversation: {}", conversation_id);

            // Check for WebSocket upgrade
            let upgrade_header = req.headers().get("upgrade")
                .and_then(|v| v.to_str().ok())
                .unwrap_or("");

            if upgrade_header != "websocket" {
                return Ok(Response::builder()
                    .status(StatusCode::BAD_REQUEST)
                    .body(Body::from("Expected WebSocket upgrade"))
                    .unwrap());
            }

            // Get WebSocket key from request
            let key = req.headers().get("sec-websocket-key")
                .and_then(|v| v.to_str().ok())
                .unwrap_or("");

            // Generate accept key
            let accept_key = {
                use sha1::{Sha1, Digest};
                use base64::{Engine as _, engine::general_purpose};
                let mut hasher = Sha1::new();
                hasher.update(key.as_bytes());
                hasher.update(b"258EAFA5-E914-47DA-95CA-C5AB0DC85B11");
                let hash = hasher.finalize();
                general_purpose::STANDARD.encode(hash)
            };

            // Clone state for the WebSocket handler
            let llama_state_ws = llama_state.clone();

            // Spawn WebSocket handler on the upgraded connection
            tokio::spawn(async move {
                match hyper::upgrade::on(req).await {
                    Ok(upgraded) => {
                        if let Err(e) = handle_conversation_watch(upgraded, conversation_id, llama_state_ws).await {
                            eprintln!("[CONV-WATCH ERROR] {}", e);
                        }
                    }
                    Err(e) => {
                        eprintln!("[CONV-WATCH UPGRADE ERROR] {}", e);
                    }
                }
            });

            // Return 101 Switching Protocols
            Response::builder()
                .status(StatusCode::SWITCHING_PROTOCOLS)
                .header("upgrade", "websocket")
                .header("connection", "upgrade")
                .header("sec-websocket-accept", accept_key)
                .body(Body::empty())
                .unwrap()
        }

        (&Method::GET, "/api/config") => {
            // Load current configuration from file or use defaults
            let config = load_config();
            
            match serde_json::to_string(&config) {
                Ok(config_json) => {
                    Response::builder()
                        .status(StatusCode::OK)
                        .header("content-type", "application/json")
                        .header("access-control-allow-origin", "*")
                        .body(Body::from(config_json))
                        .unwrap()
                }
                Err(_) => {
                    Response::builder()
                        .status(StatusCode::INTERNAL_SERVER_ERROR)
                        .header("content-type", "application/json")
                        .header("access-control-allow-origin", "*")
                        .body(Body::from(r#"{"error":"Failed to serialize configuration"}"#))
                        .unwrap()
                }
            }
        }
        
        (&Method::POST, "/api/config") => {
            // Parse request body for configuration update
            let body_bytes = match hyper::body::to_bytes(req.into_body()).await {
                Ok(bytes) => bytes,
                Err(_) => {
                    return Ok(Response::builder()
                        .status(StatusCode::BAD_REQUEST)
                        .header("content-type", "application/json")
                        .header("access-control-allow-origin", "*")
                        .body(Body::from(r#"{"error":"Failed to read request body"}"#))
                        .unwrap());
                }
            };

            // Parse incoming config
            let incoming_config: SamplerConfig = match serde_json::from_slice(&body_bytes) {
                Ok(config) => config,
                Err(_) => {
                    return Ok(Response::builder()
                        .status(StatusCode::BAD_REQUEST)
                        .header("content-type", "application/json")
                        .header("access-control-allow-origin", "*")
                        .body(Body::from(r#"{"error":"Invalid JSON format"}"#))
                        .unwrap());
                }
            };

            // Load existing config to preserve model_history
            let mut existing_config = load_config();

            // Update fields from incoming config, but preserve model_history
            existing_config.sampler_type = incoming_config.sampler_type;
            existing_config.temperature = incoming_config.temperature;
            existing_config.top_p = incoming_config.top_p;
            existing_config.top_k = incoming_config.top_k;
            existing_config.mirostat_tau = incoming_config.mirostat_tau;
            existing_config.mirostat_eta = incoming_config.mirostat_eta;
            existing_config.model_path = incoming_config.model_path;
            existing_config.system_prompt = incoming_config.system_prompt;
            existing_config.context_size = incoming_config.context_size;
            existing_config.stop_tokens = incoming_config.stop_tokens;
            // Note: model_history is NOT updated from incoming config

            // Save merged configuration to file
            let config_path = "assets/config.json";
            if let Err(_) = fs::create_dir_all("assets") {
                return Ok(Response::builder()
                    .status(StatusCode::INTERNAL_SERVER_ERROR)
                    .header("content-type", "application/json")
                    .header("access-control-allow-origin", "*")
                    .body(Body::from(r#"{"error":"Failed to create config directory"}"#))
                    .unwrap());
            }

            match fs::write(config_path, serde_json::to_string_pretty(&existing_config).unwrap_or_default()) {
                Ok(_) => {
                    Response::builder()
                        .status(StatusCode::OK)
                        .header("content-type", "application/json")
                        .header("access-control-allow-origin", "*")
                        .body(Body::from(r#"{"success":true}"#))
                        .unwrap()
                }
                Err(_) => {
                    Response::builder()
                        .status(StatusCode::INTERNAL_SERVER_ERROR)
                        .header("content-type", "application/json")
                        .header("access-control-allow-origin", "*")
                        .body(Body::from(r#"{"error":"Failed to save configuration"}"#))
                        .unwrap()
                }
            }
        }
        
        (&Method::GET, path) if path.starts_with("/api/conversation/") => {
            // Extract filename from path: /api/conversation/{filename}
            let filename = &path[18..]; // Remove "/api/conversation/"
            let conversations_dir = "assets/conversations";
            let file_path = format!("{}/{}", conversations_dir, filename);
            
            match fs::read_to_string(&file_path) {
                Ok(content) => {
                    let messages = parse_conversation_to_messages(&content);
                    let response = ConversationContentResponse {
                        content: content.clone(),
                        messages,
                    };
                    
                    let response_json = match serde_json::to_string(&response) {
                        Ok(json) => json,
                        Err(_) => r#"{"content":"","messages":[]}"#.to_string(),
                    };
                    
                    Response::builder()
                        .status(StatusCode::OK)
                        .header("content-type", "application/json")
                        .header("access-control-allow-origin", "*")
                        .body(Body::from(response_json))
                        .unwrap()
                }
                Err(_) => {
                    Response::builder()
                        .status(StatusCode::NOT_FOUND)
                        .header("content-type", "application/json")
                        .header("access-control-allow-origin", "*")
                        .body(Body::from(r#"{"error":"Conversation not found"}"#))
                        .unwrap()
                }
            }
        }
        
        (&Method::GET, "/api/model/info") => {
            println!("[DEBUG] /api/model/info endpoint hit");

            // Extract model path from query parameters
            let query = req.uri().query().unwrap_or("");
            println!("[DEBUG] Query string: {}", query);

            let mut model_path = "";

            for param in query.split('&') {
                if let Some((key, value)) = param.split_once('=') {
                    if key == "path" {
                        // URL decode the path
                        model_path = value;
                        println!("[DEBUG] Found path parameter (encoded): {}", model_path);
                        break;
                    }
                }
            }

            if model_path.is_empty() {
                println!("[DEBUG] ERROR: No path parameter provided");
                return Ok(Response::builder()
                    .status(StatusCode::BAD_REQUEST)
                    .header("content-type", "application/json")
                    .header("access-control-allow-origin", "*")
                    .body(Body::from(r#"{"error":"Model path is required"}"#))
                    .unwrap());
            }

            // URL decode the path properly
            let decoded_path = urlencoding::decode(model_path).unwrap_or(std::borrow::Cow::Borrowed(model_path));
            println!("[DEBUG] Decoded path: {}", decoded_path);

            // Check if file exists
            let path_obj = std::path::Path::new(&*decoded_path);
            let exists = path_obj.exists();
            println!("[DEBUG] File exists: {}", exists);
            println!("[DEBUG] Path is file: {}", path_obj.is_file());
            println!("[DEBUG] Path is dir: {}", path_obj.is_dir());

            if !exists {
                println!("[DEBUG] ERROR: File does not exist at path: {}", decoded_path);
                return Ok(Response::builder()
                    .status(StatusCode::NOT_FOUND)
                    .header("content-type", "application/json")
                    .header("access-control-allow-origin", "*")
                    .body(Body::from(r#"{"error":"Model file not found"}"#))
                    .unwrap());
            }

            // Check if path is a directory
            if path_obj.is_dir() {
                println!("[DEBUG] Path is a directory, scanning for .gguf files...");

                // Find all .gguf files in the directory
                let mut gguf_files = Vec::new();
                if let Ok(entries) = fs::read_dir(path_obj) {
                    for entry in entries.flatten() {
                        let entry_path = entry.path();
                        if entry_path.is_file() {
                            if let Some(ext) = entry_path.extension() {
                                if ext.eq_ignore_ascii_case("gguf") {
                                    if let Some(filename) = entry_path.file_name().and_then(|n| n.to_str()) {
                                        gguf_files.push(filename.to_string());
                                    }
                                }
                            }
                        }
                    }
                }

                let response_json = if gguf_files.is_empty() {
                    serde_json::json!({
                        "error": "This is a directory. No .gguf files found in this directory.",
                        "is_directory": true,
                        "suggestions": []
                    })
                } else {
                    serde_json::json!({
                        "error": format!("This is a directory. Found {} .gguf file(s). Please select one:", gguf_files.len()),
                        "is_directory": true,
                        "suggestions": gguf_files
                    })
                };

                println!("[DEBUG] Returning directory error with {} suggestions", gguf_files.len());
                return Ok(Response::builder()
                    .status(StatusCode::BAD_REQUEST)
                    .header("content-type", "application/json")
                    .header("access-control-allow-origin", "*")
                    .body(Body::from(response_json.to_string()))
                    .unwrap());
            }

            // Check if file has .gguf extension
            if let Some(ext) = path_obj.extension() {
                if !ext.eq_ignore_ascii_case("gguf") {
                    println!("[DEBUG] ERROR: File is not a .gguf file");
                    return Ok(Response::builder()
                        .status(StatusCode::BAD_REQUEST)
                        .header("content-type", "application/json")
                        .header("access-control-allow-origin", "*")
                        .body(Body::from(r#"{"error":"File must have .gguf extension"}"#))
                        .unwrap());
                }
            } else {
                println!("[DEBUG] ERROR: File has no extension");
                return Ok(Response::builder()
                    .status(StatusCode::BAD_REQUEST)
                    .header("content-type", "application/json")
                    .header("access-control-allow-origin", "*")
                    .body(Body::from(r#"{"error":"File must have .gguf extension"}"#))
                    .unwrap());
            }
            
            // Extract basic model information
            let file_metadata = match fs::metadata(&*decoded_path) {
                Ok(metadata) => metadata,
                Err(_) => {
                    return Ok(Response::builder()
                        .status(StatusCode::INTERNAL_SERVER_ERROR)
                        .header("content-type", "application/json")
                        .header("access-control-allow-origin", "*")
                        .body(Body::from(r#"{"error":"Failed to read file metadata"}"#))
                        .unwrap());
                }
            };
            
            let file_size_bytes = file_metadata.len();
            let file_size = if file_size_bytes >= 1_073_741_824 {
                format!("{:.1} GB", file_size_bytes as f64 / 1_073_741_824.0)
            } else if file_size_bytes >= 1_048_576 {
                format!("{:.1} MB", file_size_bytes as f64 / 1_048_576.0)
            } else {
                format!("{} bytes", file_size_bytes)
            };
            
            let filename = std::path::Path::new(&*decoded_path)
                .file_name()
                .and_then(|n| n.to_str())
                .unwrap_or("unknown");
            
            // Try to extract model information from filename patterns
            let mut architecture = "Unknown";
            let mut parameters = "Unknown";
            let mut quantization = "Unknown";
            
            // Common GGUF naming patterns
            if filename.contains("llama") || filename.contains("Llama") {
                architecture = "LLaMA";
            } else if filename.contains("mistral") || filename.contains("Mistral") {
                architecture = "Mistral";
            } else if filename.contains("qwen") || filename.contains("Qwen") {
                architecture = "Qwen";
            } else if filename.contains("phi") || filename.contains("Phi") {
                architecture = "Phi";
            }
            
            // Extract parameter count
            if filename.contains("7b") || filename.contains("7B") {
                parameters = "7B";
            } else if filename.contains("13b") || filename.contains("13B") {
                parameters = "13B";
            } else if filename.contains("70b") || filename.contains("70B") {
                parameters = "70B";
            } else if filename.contains("1.5b") || filename.contains("1.5B") {
                parameters = "1.5B";
            } else if filename.contains("3b") || filename.contains("3B") {
                parameters = "3B";
            }
            
            // Extract quantization
            if filename.contains("q4_0") || filename.contains("Q4_0") {
                quantization = "Q4_0";
            } else if filename.contains("q4_1") || filename.contains("Q4_1") {
                quantization = "Q4_1";
            } else if filename.contains("q5_0") || filename.contains("Q5_0") {
                quantization = "Q5_0";
            } else if filename.contains("q5_1") || filename.contains("Q5_1") {
                quantization = "Q5_1";
            } else if filename.contains("q8_0") || filename.contains("Q8_0") {
                quantization = "Q8_0";
            } else if filename.contains("f16") || filename.contains("F16") {
                quantization = "F16";
            } else if filename.contains("f32") || filename.contains("F32") {
                quantization = "F32";
            }
            
            // Estimate total layers based on model size
            let model_size_gb = file_size_bytes as f64 / (1024.0 * 1024.0 * 1024.0);
            let estimated_total_layers = if model_size_gb < 8.0 {
                36  // Small models (7B and below)
            } else if model_size_gb < 15.0 {
                45  // Medium models (13B)
            } else if model_size_gb < 25.0 {
                60  // Large models (30B)
            } else {
                80  // Very large models (70B+)
            };

            // Build base model info
            let mut model_info = serde_json::json!({
                "name": filename,
                "architecture": architecture,
                "parameters": parameters,
                "quantization": quantization,
                "file_size": file_size,
                "context_length": "Variable",
                "path": decoded_path.to_string(),
                "estimated_layers": estimated_total_layers
            });

            // Try to parse GGUF metadata
            if let Ok(file) = fs::File::open(&*decoded_path) {
                let mut reader = BufReader::new(file);

                if let Ok(header) = GgufHeader::parse(&mut reader) {
                    if let Ok(metadata) = GgufReader::read_metadata(&mut reader, header.n_kv) {
                        // Debug: Print all available metadata keys and values
                        println!("=== GGUF Metadata Found ===");
                        for (key, value) in metadata.iter() {
                            let val_str = match value {
                                Value::String(s) => format!("\"{}\"", s),
                                Value::Uint8(n) => n.to_string(),
                                Value::Uint16(n) => n.to_string(),
                                Value::Uint32(n) => n.to_string(),
                                Value::Uint64(n) => n.to_string(),
                                Value::Int8(n) => n.to_string(),
                                Value::Int16(n) => n.to_string(),
                                Value::Int32(n) => n.to_string(),
                                Value::Int64(n) => n.to_string(),
                                Value::Float32(f) => f.to_string(),
                                Value::Float64(f) => f.to_string(),
                                Value::Bool(b) => b.to_string(),
                                Value::Array(_, items) => format!("[Array with {} items]", items.len()),
                            };
                            println!("  {} = {}", key, val_str);
                        }
                        println!("================================");

                        // Helper to get metadata value as string
                        let get_meta_string = |key: &str| -> Option<String> {
                            metadata.get(key).and_then(|v| match v {
                                Value::String(s) => Some(s.clone()),
                                Value::Uint8(n) => Some(n.to_string()),
                                Value::Uint16(n) => Some(n.to_string()),
                                Value::Uint32(n) => Some(n.to_string()),
                                Value::Uint64(n) => Some(n.to_string()),
                                Value::Int8(n) => Some(n.to_string()),
                                Value::Int16(n) => Some(n.to_string()),
                                Value::Int32(n) => Some(n.to_string()),
                                Value::Int64(n) => Some(n.to_string()),
                                Value::Float32(f) => Some(f.to_string()),
                                Value::Float64(f) => Some(f.to_string()),
                                Value::Bool(b) => Some(b.to_string()),
                                _ => None,
                            })
                        };

                        // Create a metadata object with all values
                        let mut all_metadata = serde_json::Map::new();
                        for (key, value) in metadata.iter() {
                            let val_json = match value {
                                Value::String(s) => serde_json::json!(s),
                                Value::Uint8(n) => serde_json::json!(n),
                                Value::Uint16(n) => serde_json::json!(n),
                                Value::Uint32(n) => serde_json::json!(n),
                                Value::Uint64(n) => serde_json::json!(n),
                                Value::Int8(n) => serde_json::json!(n),
                                Value::Int16(n) => serde_json::json!(n),
                                Value::Int32(n) => serde_json::json!(n),
                                Value::Int64(n) => serde_json::json!(n),
                                Value::Float32(f) => serde_json::json!(f),
                                Value::Float64(f) => serde_json::json!(f),
                                Value::Bool(b) => serde_json::json!(b),
                                Value::Array(_, _) => serde_json::json!("[Array]"),
                            };
                            all_metadata.insert(key.clone(), val_json);
                        }
                        model_info["gguf_metadata"] = serde_json::json!(all_metadata);

                        // Get architecture
                        let arch = get_meta_string("general.architecture")
                            .unwrap_or_else(|| "llama".to_string());

                        // Update architecture
                        model_info["architecture"] = serde_json::json!(arch.clone());

                        // Detect tool calling format based on architecture and model name
                        let model_name = get_meta_string("general.name").unwrap_or_default().to_lowercase();
                        let tool_format = if arch.contains("mistral") || model_name.contains("mistral") || model_name.contains("devstral") {
                            "mistral"
                        } else if arch.contains("llama") && (model_name.contains("llama-3") || model_name.contains("llama3")) {
                            "llama3"
                        } else if arch.contains("qwen") || model_name.contains("qwen") {
                            "qwen"
                        } else if arch.contains("llama") {
                            // Older llama models don't support tools
                            "unknown"
                        } else {
                            "unknown"
                        };
                        model_info["tool_format"] = serde_json::json!(tool_format);

                        // Core model information
                        if let Some(val) = get_meta_string("general.name") {
                            model_info["general_name"] = serde_json::json!(val);
                        }
                        if let Some(val) = get_meta_string("general.author") {
                            model_info["author"] = serde_json::json!(val);
                        }
                        if let Some(val) = get_meta_string("general.version") {
                            model_info["version"] = serde_json::json!(val);
                        }
                        if let Some(val) = get_meta_string("general.organization") {
                            model_info["organization"] = serde_json::json!(val);
                        }
                        if let Some(val) = get_meta_string("general.description") {
                            model_info["description"] = serde_json::json!(val);
                        }
                        if let Some(val) = get_meta_string("general.license") {
                            model_info["license"] = serde_json::json!(val);
                        }
                        if let Some(val) = get_meta_string("general.url") {
                            model_info["url"] = serde_json::json!(val);
                        }
                        if let Some(val) = get_meta_string("general.repo_url") {
                            model_info["repo_url"] = serde_json::json!(val);
                        }
                        if let Some(val) = get_meta_string("general.file_type") {
                            model_info["file_type"] = serde_json::json!(val);
                        }
                        if let Some(val) = get_meta_string("general.quantization_version") {
                            model_info["quantization_version"] = serde_json::json!(val);
                        }

                        // Context length - try multiple keys
                        let context_keys = vec![
                            format!("{}.context_length", arch),
                            "llama.context_length".to_string(),
                            "context_length".to_string(),
                        ];
                        for key in &context_keys {
                            if let Some(val) = get_meta_string(key) {
                                model_info["context_length"] = serde_json::json!(val);
                                break;
                            }
                        }

                        // Architecture-specific fields
                        if let Some(val) = get_meta_string(&format!("{}.embedding_length", arch)) {
                            model_info["embedding_length"] = serde_json::json!(val);
                        }
                        if let Some(val) = get_meta_string(&format!("{}.block_count", arch)) {
                            model_info["block_count"] = serde_json::json!(val.clone());
                            // Use actual block count for layers
                            if let Ok(block_count) = val.parse::<u32>() {
                                model_info["estimated_layers"] = serde_json::json!(block_count);
                            }
                        }
                        if let Some(val) = get_meta_string(&format!("{}.feed_forward_length", arch)) {
                            model_info["feed_forward_length"] = serde_json::json!(val);
                        }
                        if let Some(val) = get_meta_string(&format!("{}.attention.head_count", arch)) {
                            model_info["attention_head_count"] = serde_json::json!(val);
                        }
                        if let Some(val) = get_meta_string(&format!("{}.attention.head_count_kv", arch)) {
                            model_info["attention_head_count_kv"] = serde_json::json!(val);
                        }
                        if let Some(val) = get_meta_string(&format!("{}.attention.layer_norm_rms_epsilon", arch)) {
                            model_info["layer_norm_epsilon"] = serde_json::json!(val);
                        }
                        if let Some(val) = get_meta_string(&format!("{}.rope.dimension_count", arch)) {
                            model_info["rope_dimension_count"] = serde_json::json!(val);
                        }
                        if let Some(val) = get_meta_string(&format!("{}.rope.freq_base", arch)) {
                            model_info["rope_freq_base"] = serde_json::json!(val);
                        }

                        // Tokenizer information
                        if let Some(val) = get_meta_string("tokenizer.ggml.model") {
                            model_info["tokenizer_model"] = serde_json::json!(val);
                        }
                        if let Some(val) = get_meta_string("tokenizer.ggml.bos_token_id") {
                            model_info["bos_token_id"] = serde_json::json!(val);
                        }
                        if let Some(val) = get_meta_string("tokenizer.ggml.eos_token_id") {
                            model_info["eos_token_id"] = serde_json::json!(val);
                        }
                        if let Some(val) = get_meta_string("tokenizer.ggml.padding_token_id") {
                            model_info["padding_token_id"] = serde_json::json!(val);
                        }
                        if let Some(val) = get_meta_string("tokenizer.chat_template") {
                            model_info["chat_template"] = serde_json::json!(val);

                            // Extract default system prompt from chat template
                            // Look for: {%- set default_system_message = '...' %}
                            if let Some(start_idx) = val.find("set default_system_message = '") {
                                let after_start = &val[start_idx + "set default_system_message = '".len()..];
                                if let Some(end_idx) = after_start.find("' %}") {
                                    let default_prompt = &after_start[..end_idx];
                                    model_info["default_system_prompt"] = serde_json::json!(default_prompt);
                                }
                            }
                        }
                    }
                }
            }
            
            Response::builder()
                .status(StatusCode::OK)
                .header("content-type", "application/json")
                .header("access-control-allow-origin", "*")
                .body(Body::from(model_info.to_string()))
                .unwrap()
        }
        
        (&Method::GET, "/api/browse") => {
            // Parse query parameters for path
            let query = req.uri().query().unwrap_or("");
            let mut browse_path = "/app/models"; // Default path
            
            // Simple query parameter parsing
            for param in query.split('&') {
                if let Some((key, value)) = param.split_once('=') {
                    if key == "path" {
                        // Simple path assignment (assume already decoded by browser)
                        browse_path = value;
                    }
                }
            }
            
            // Security: ensure path is within allowed directories
            let allowed_paths = ["/app/models", "/app"];
            let is_allowed = allowed_paths.iter().any(|&allowed| {
                browse_path.starts_with(allowed)
            });
            
            if !is_allowed {
                return Ok(Response::builder()
                    .status(StatusCode::FORBIDDEN)
                    .header("content-type", "application/json")
                    .header("access-control-allow-origin", "*")
                    .body(Body::from(r#"{"error":"Path not allowed"}"#))
                    .unwrap());
            }
            
            let mut files = Vec::new();
            let current_path = browse_path.to_string();
            let parent_path = if browse_path != "/app/models" && browse_path != "/app" {
                std::path::Path::new(browse_path)
                    .parent()
                    .and_then(|p| p.to_str())
                    .map(|s| s.to_string())
            } else {
                None
            };
            
            match fs::read_dir(browse_path) {
                Ok(entries) => {
                    for entry in entries {
                        if let Ok(entry) = entry {
                            let path = entry.path();
                            if let (Some(name), Some(path_str)) = (
                                path.file_name().and_then(|n| n.to_str()),
                                path.to_str()
                            ) {
                                let is_directory = path.is_dir();
                                let size = if !is_directory {
                                    entry.metadata().ok().map(|m| m.len())
                                } else {
                                    None
                                };
                                
                                files.push(FileItem {
                                    name: name.to_string(),
                                    path: path_str.to_string(),
                                    is_directory,
                                    size,
                                });
                            }
                        }
                    }
                    
                    // Sort: directories first, then files, both alphabetically
                    files.sort_by(|a, b| {
                        match (a.is_directory, b.is_directory) {
                            (true, false) => std::cmp::Ordering::Less,
                            (false, true) => std::cmp::Ordering::Greater,
                            _ => a.name.to_lowercase().cmp(&b.name.to_lowercase()),
                        }
                    });
                }
                Err(e) => {
                    eprintln!("Failed to read directory {}: {}", browse_path, e);
                    return Ok(Response::builder()
                        .status(StatusCode::NOT_FOUND)
                        .header("content-type", "application/json")
                        .header("access-control-allow-origin", "*")
                        .body(Body::from(r#"{"error":"Directory not found"}"#))
                        .unwrap());
                }
            }
            
            let response = BrowseFilesResponse {
                files,
                current_path,
                parent_path,
            };
            
            let response_json = match serde_json::to_string(&response) {
                Ok(json) => json,
                Err(_) => r#"{"files":[],"current_path":"/app/models"}"#.to_string(),
            };
            
            Response::builder()
                .status(StatusCode::OK)
                .header("content-type", "application/json")
                .header("access-control-allow-origin", "*")
                .body(Body::from(response_json))
                .unwrap()
        }
        
        (&Method::GET, "/api/model/status") => {
            
            {
                if let Some(state) = llama_state {
                    let status = get_model_status(&state);
                    let response_json = match serde_json::to_string(&status) {
                        Ok(json) => json,
                        Err(_) => r#"{"loaded":false,"model_path":null,"last_used":null,"memory_usage_mb":null}"#.to_string(),
                    };

                    Response::builder()
                        .status(StatusCode::OK)
                        .header("content-type", "application/json")
                        .header("access-control-allow-origin", "*")
                        .body(Body::from(response_json))
                        .unwrap()
                } else {
                    Response::builder()
                        .status(StatusCode::SERVICE_UNAVAILABLE)
                        .header("content-type", "application/json")
                        .header("access-control-allow-origin", "*")
                        .body(Body::from(r#"{"loaded":false,"model_path":null,"last_used":null,"memory_usage_mb":null}"#))
                        .unwrap()
                }
            }

            #[cfg(feature = "mock")]
            {
                Response::builder()
                    .status(StatusCode::OK)
                    .header("content-type", "application/json")
                    .header("access-control-allow-origin", "*")
                    .body(Body::from(r#"{"loaded":false,"model_path":null,"last_used":null,"memory_usage_mb":null}"#))
                    .unwrap()
            }
        }

        (&Method::GET, "/api/model/history") => {
            // Load config and return model history
            let config = load_config();
            let response_json = match serde_json::to_string(&config.model_history) {
                Ok(json) => json,
                Err(_) => "[]".to_string(),
            };

            Response::builder()
                .status(StatusCode::OK)
                .header("content-type", "application/json")
                .header("access-control-allow-origin", "*")
                .body(Body::from(response_json))
                .unwrap()
        }

        (&Method::POST, "/api/model/history") => {
            // Add a model path to history
            let body_bytes = match hyper::body::to_bytes(req.into_body()).await {
                Ok(bytes) => bytes,
                Err(e) => {
                    println!("[DEBUG] Failed to read request body: {}", e);
                    return Ok(Response::builder()
                        .status(StatusCode::BAD_REQUEST)
                        .header("content-type", "application/json")
                        .header("access-control-allow-origin", "*")
                        .body(Body::from(r#"{"success":false,"message":"Failed to read request body"}"#))
                        .unwrap());
                }
            };

            #[derive(Deserialize)]
            struct AddHistoryRequest {
                model_path: String,
            }

            let request: AddHistoryRequest = match serde_json::from_slice(&body_bytes) {
                Ok(req) => req,
                Err(e) => {
                    println!("[DEBUG] JSON parsing error: {}", e);
                    return Ok(Response::builder()
                        .status(StatusCode::BAD_REQUEST)
                        .header("content-type", "application/json")
                        .header("access-control-allow-origin", "*")
                        .body(Body::from(r#"{"success":false,"message":"Invalid JSON format"}"#))
                        .unwrap());
                }
            };

            // Add to history
            add_to_model_history(&request.model_path);

            Response::builder()
                .status(StatusCode::OK)
                .header("content-type", "application/json")
                .header("access-control-allow-origin", "*")
                .body(Body::from(r#"{"success":true}"#))
                .unwrap()
        }

        (&Method::POST, "/api/model/load") => {
            println!("[DEBUG] /api/model/load endpoint hit");

            
            {
                if let Some(state) = llama_state {
                    // Parse request body
                    let body_bytes = match hyper::body::to_bytes(req.into_body()).await {
                        Ok(bytes) => bytes,
                        Err(e) => {
                            println!("[DEBUG] Failed to read request body: {}", e);
                            return Ok(Response::builder()
                                .status(StatusCode::BAD_REQUEST)
                                .header("content-type", "application/json")
                                .header("access-control-allow-origin", "*")
                                .body(Body::from(r#"{"success":false,"message":"Failed to read request body"}"#))
                                .unwrap());
                        }
                    };

                    println!("[DEBUG] Request body: {}", String::from_utf8_lossy(&body_bytes));

                    let load_request: ModelLoadRequest = match serde_json::from_slice(&body_bytes) {
                        Ok(req) => req,
                        Err(e) => {
                            println!("[DEBUG] JSON parsing error in model/load: {}", e);
                            println!("[DEBUG] Raw body was: {}", String::from_utf8_lossy(&body_bytes));
                            return Ok(Response::builder()
                                .status(StatusCode::BAD_REQUEST)
                                .header("content-type", "application/json")
                                .header("access-control-allow-origin", "*")
                                .body(Body::from(r#"{"success":false,"message":"Invalid JSON format"}"#))
                                .unwrap());
                        }
                    };

                    // Attempt to load the model
                    match load_model(state.clone(), &load_request.model_path).await {
                        Ok(_) => {
                            // Add to model history on successful load
                            add_to_model_history(&load_request.model_path);

                            let status = get_model_status(&state);
                            let response = ModelResponse {
                                success: true,
                                message: format!("Model loaded successfully from {}", load_request.model_path),
                                status: Some(status),
                            };

                            let response_json = match serde_json::to_string(&response) {
                                Ok(json) => json,
                                Err(_) => r#"{"success":true,"message":"Model loaded successfully","status":null}"#.to_string(),
                            };

                            Response::builder()
                                .status(StatusCode::OK)
                                .header("content-type", "application/json")
                                .header("access-control-allow-origin", "*")
                                .body(Body::from(response_json))
                                .unwrap()
                        }
                        Err(e) => {
                            let response = ModelResponse {
                                success: false,
                                message: format!("Failed to load model: {}", e),
                                status: None,
                            };
                            
                            let response_json = match serde_json::to_string(&response) {
                                Ok(json) => json,
                                Err(_) => format!(r#"{{"success":false,"message":"Failed to load model: {}","status":null}}"#, e),
                            };
                            
                            Response::builder()
                                .status(StatusCode::INTERNAL_SERVER_ERROR)
                                .header("content-type", "application/json")
                                .header("access-control-allow-origin", "*")
                                .body(Body::from(response_json))
                                .unwrap()
                        }
                    }
                } else {
                    Response::builder()
                        .status(StatusCode::SERVICE_UNAVAILABLE)
                        .header("content-type", "application/json")
                        .header("access-control-allow-origin", "*")
                        .body(Body::from(r#"{"success":false,"message":"LLaMA state not available"}"#))
                        .unwrap()
                }
            }
            
            #[cfg(feature = "mock")]
            {
                Response::builder()
                    .status(StatusCode::SERVICE_UNAVAILABLE)
                    .header("content-type", "application/json")
                    .header("access-control-allow-origin", "*")
                    .body(Body::from(r#"{"success":false,"message":"Model loading not available (mock feature enabled)"}"#))
                    .unwrap()
            }
        }
        
        (&Method::POST, "/api/model/unload") => {
            
            {
                if let Some(state) = llama_state {
                    match unload_model(state.clone()).await {
                        Ok(_) => {
                            let status = get_model_status(&state);
                            let response = ModelResponse {
                                success: true,
                                message: "Model unloaded successfully".to_string(),
                                status: Some(status),
                            };
                            
                            let response_json = match serde_json::to_string(&response) {
                                Ok(json) => json,
                                Err(_) => r#"{"success":true,"message":"Model unloaded successfully","status":null}"#.to_string(),
                            };
                            
                            Response::builder()
                                .status(StatusCode::OK)
                                .header("content-type", "application/json")
                                .header("access-control-allow-origin", "*")
                                .body(Body::from(response_json))
                                .unwrap()
                        }
                        Err(e) => {
                            let response = ModelResponse {
                                success: false,
                                message: format!("Failed to unload model: {}", e),
                                status: None,
                            };
                            
                            let response_json = match serde_json::to_string(&response) {
                                Ok(json) => json,
                                Err(_) => format!(r#"{{"success":false,"message":"Failed to unload model: {}","status":null}}"#, e),
                            };
                            
                            Response::builder()
                                .status(StatusCode::INTERNAL_SERVER_ERROR)
                                .header("content-type", "application/json")
                                .header("access-control-allow-origin", "*")
                                .body(Body::from(response_json))
                                .unwrap()
                        }
                    }
                } else {
                    Response::builder()
                        .status(StatusCode::SERVICE_UNAVAILABLE)
                        .header("content-type", "application/json")
                        .header("access-control-allow-origin", "*")
                        .body(Body::from(r#"{"success":false,"message":"LLaMA state not available"}"#))
                        .unwrap()
                }
            }
            
            #[cfg(feature = "mock")]
            {
                Response::builder()
                    .status(StatusCode::SERVICE_UNAVAILABLE)
                    .header("content-type", "application/json")
                    .header("access-control-allow-origin", "*")
                    .body(Body::from(r#"{"success":false,"message":"Model unloading not available (mock feature enabled)"}"#))
                    .unwrap()
            }
        }
        
        (&Method::POST, "/api/upload") => {
            // Extract headers before consuming the request body
            let content_disposition = req.headers().get("content-disposition")
                .and_then(|h| h.to_str().ok())
                .unwrap_or("")
                .to_string();
                
            let query = req.uri().query().unwrap_or("").to_string();

            // Handle file upload
            let body_bytes = match hyper::body::to_bytes(req.into_body()).await {
                Ok(bytes) => bytes,
                Err(_) => {
                    return Ok(Response::builder()
                        .status(StatusCode::BAD_REQUEST)
                        .header("content-type", "application/json")
                        .header("access-control-allow-origin", "*")
                        .body(Body::from(r#"{"success":false,"message":"Failed to read request body"}"#))
                        .unwrap());
                }
            };
            
            let filename = if content_disposition.contains("filename=") {
                content_disposition
                    .split("filename=")
                    .nth(1)
                    .and_then(|s| s.split(';').next())
                    .map(|s| s.trim_matches('"'))
                    .unwrap_or("uploaded_model.gguf")
            } else {
                // Try to get filename from query parameter
                let mut filename = "uploaded_model.gguf";
                for param in query.split('&') {
                    if let Some((key, value)) = param.split_once('=') {
                        if key == "filename" {
                            filename = value;
                            break;
                        }
                    }
                }
                filename
            };

            // Ensure the filename ends with .gguf
            let filename = if filename.ends_with(".gguf") {
                filename.to_string()
            } else {
                format!("{}.gguf", filename)
            };

            // Save file to models directory
            let file_path = format!("/app/models/{}", filename);
            match fs::write(&file_path, &body_bytes) {
                Ok(_) => {
                    let response = serde_json::json!({
                        "success": true,
                        "message": "File uploaded successfully",
                        "file_path": file_path
                    });
                    
                    Response::builder()
                        .status(StatusCode::OK)
                        .header("content-type", "application/json")
                        .header("access-control-allow-origin", "*")
                        .body(Body::from(response.to_string()))
                        .unwrap()
                }
                Err(e) => {
                    let response = serde_json::json!({
                        "success": false,
                        "message": format!("Failed to save file: {}", e)
                    });
                    
                    Response::builder()
                        .status(StatusCode::INTERNAL_SERVER_ERROR)
                        .header("content-type", "application/json")
                        .header("access-control-allow-origin", "*")
                        .body(Body::from(response.to_string()))
                        .unwrap()
                }
            }
        }
        
        (&Method::GET, "/api/conversations") => {
            // Fetch conversation files from assets/conversations directory
            let conversations_dir = "assets/conversations";
            let mut conversations = Vec::new();

            match fs::read_dir(conversations_dir) {
                Ok(entries) => {
                    for entry in entries {
                        if let Ok(entry) = entry {
                            let path = entry.path();
                            if path.is_file() && path.extension().map_or(false, |ext| ext == "txt") {
                                if let Some(filename) = path.file_name().and_then(|n| n.to_str()) {
                                    // Extract timestamp from filename (chat_YYYY-MM-DD-HH-mm-ss-SSS.txt)
                                    if filename.starts_with("chat_") && filename.ends_with(".txt") {
                                        let timestamp_part = &filename[5..filename.len()-4]; // Remove "chat_" and ".txt"

                                        conversations.push(ConversationFile {
                                            name: filename.to_string(),
                                            display_name: format!("Chat {}", timestamp_part),
                                            timestamp: timestamp_part.to_string(),
                                        });
                                    }
                                }
                            }
                        }
                    }
                }
                Err(e) => {
                    eprintln!("Failed to read conversations directory: {}", e);
                }
            }

            // Sort conversations by timestamp (newest first)
            conversations.sort_by(|a, b| b.timestamp.cmp(&a.timestamp));

            let response = ConversationsResponse { conversations };
            let response_json = match serde_json::to_string(&response) {
                Ok(json) => json,
                Err(_) => r#"{"conversations":[]}"#.to_string(),
            };

            Response::builder()
                .status(StatusCode::OK)
                .header("content-type", "application/json")
                .header("access-control-allow-origin", "*")
                .body(Body::from(response_json))
                .unwrap()
        }

        (&Method::DELETE, path) if path.starts_with("/api/conversations/") => {
            // Extract filename from path
            let filename = &path["/api/conversations/".len()..];

            // Validate filename to prevent path traversal
            if filename.contains("..") || filename.contains("/") || filename.contains("\\") {
                return Ok(Response::builder()
                    .status(StatusCode::BAD_REQUEST)
                    .header("content-type", "application/json")
                    .header("access-control-allow-origin", "*")
                    .body(Body::from(r#"{"error":"Invalid filename"}"#))
                    .unwrap());
            }

            // Only allow deleting .txt files that start with "chat_"
            if !filename.starts_with("chat_") || !filename.ends_with(".txt") {
                return Ok(Response::builder()
                    .status(StatusCode::BAD_REQUEST)
                    .header("content-type", "application/json")
                    .header("access-control-allow-origin", "*")
                    .body(Body::from(r#"{"error":"Invalid conversation file"}"#))
                    .unwrap());
            }

            let file_path = format!("assets/conversations/{}", filename);

            match fs::remove_file(&file_path) {
                Ok(_) => {
                    println!("Deleted conversation file: {}", filename);
                    Response::builder()
                        .status(StatusCode::OK)
                        .header("content-type", "application/json")
                        .header("access-control-allow-origin", "*")
                        .body(Body::from(r#"{"success":true}"#))
                        .unwrap()
                }
                Err(e) => {
                    eprintln!("Failed to delete conversation file: {}", e);
                    Response::builder()
                        .status(StatusCode::INTERNAL_SERVER_ERROR)
                        .header("content-type", "application/json")
                        .header("access-control-allow-origin", "*")
                        .body(Body::from(r#"{"error":"Failed to delete conversation"}"#))
                        .unwrap()
                }
            }
        }

        (&Method::OPTIONS, _) => {
            Response::builder()
                .status(StatusCode::OK)
                .header("access-control-allow-origin", "*")
                .header("access-control-allow-methods", "GET, POST, DELETE, OPTIONS")
                .header("access-control-allow-headers", "content-type")
                .body(Body::empty())
                .unwrap()
        }
        
        (&Method::GET, "/") => {
            // Serve the main index.html from the built frontend
            match std::fs::read_to_string("./dist/index.html") {
                Ok(content) => Response::builder()
                    .status(StatusCode::OK)
                    .header("content-type", "text/html")
                    .body(Body::from(content))
                    .unwrap(),
                Err(_) => {
                    // Fallback HTML if dist files aren't found
                    let html = r#"<!DOCTYPE html>
<html>
<head><title>LLaMA Chat Web</title></head>
<body>
<h1>🦙 LLaMA Chat Web Server</h1>
<p>Web server is running successfully!</p>
<p>Frontend files not found. API endpoints:</p>
<ul>
<li>GET /health - Health check</li>
<li>POST /api/chat - Chat endpoint</li>
<li>GET /api/config - Configuration</li>
</ul>
</body>
</html>"#;
                    Response::builder()
                        .status(StatusCode::OK)
                        .header("content-type", "text/html")
                        .body(Body::from(html))
                        .unwrap()
                }
            }
        }
        
        (&Method::GET, path) if path.starts_with("/assets/") || path.ends_with(".svg") || path.ends_with(".ico") || path.ends_with(".png") => {
            // Serve static assets (JS, CSS, etc.)
            let file_path = format!("./dist{}", path);
            match std::fs::read(&file_path) {
                Ok(content) => {
                    let content_type = if path.ends_with(".js") {
                        "application/javascript"
                    } else if path.ends_with(".css") {
                        "text/css"
                    } else if path.ends_with(".png") {
                        "image/png"
                    } else if path.ends_with(".jpg") || path.ends_with(".jpeg") {
                        "image/jpeg"
                    } else if path.ends_with(".svg") {
                        "image/svg+xml"
                    } else {
                        "application/octet-stream"
                    };
                    
                    Response::builder()
                        .status(StatusCode::OK)
                        .header("content-type", content_type)
                        .header("cache-control", "public, max-age=31536000") // 1 year cache
                        .body(Body::from(content))
                        .unwrap()
                }
                Err(_) => {
                    Response::builder()
                        .status(StatusCode::NOT_FOUND)
                        .body(Body::from("Asset not found"))
                        .unwrap()
                }
            }
        }

        (&Method::POST, "/api/tools/execute") => {
            // Parse request body
            let body_bytes = match hyper::body::to_bytes(req.into_body()).await {
                Ok(bytes) => bytes,
                Err(_) => {
                    return Ok(Response::builder()
                        .status(StatusCode::BAD_REQUEST)
                        .header("content-type", "application/json")
                        .header("access-control-allow-origin", "*")
                        .body(Body::from(r#"{"error":"Failed to read request body"}"#))
                        .unwrap());
                }
            };

            #[derive(serde::Deserialize)]
            struct ToolExecuteRequest {
                tool_name: String,
                arguments: serde_json::Value,
            }

            let request: ToolExecuteRequest = match serde_json::from_slice(&body_bytes) {
                Ok(req) => req,
                Err(e) => {
                    println!("JSON parsing error: {}", e);
                    return Ok(Response::builder()
                        .status(StatusCode::BAD_REQUEST)
                        .header("content-type", "application/json")
                        .header("access-control-allow-origin", "*")
                        .body(Body::from(r#"{"error":"Invalid JSON format"}"#))
                        .unwrap());
                }
            };

            // Get current model's capabilities for tool translation
            let (tool_name, tool_arguments) = {
                // Access the shared state to get current chat template
                let state_guard = llama_state.as_ref().expect("LLaMA state not available");
                // Handle poisoned mutex by extracting the inner value
                let state = state_guard.lock().unwrap_or_else(|poisoned| {
                    eprintln!("[WARN] Mutex was poisoned, recovering...");
                    poisoned.into_inner()
                });
                let chat_template = state.as_ref()
                    .and_then(|s| s.chat_template_type.as_deref())
                    .unwrap_or("Unknown");
                let capabilities = web::models::get_model_capabilities(chat_template);

                // Translate tool if model doesn't support it natively
                web::models::translate_tool_for_model(
                    &request.tool_name,
                    &request.arguments,
                    &capabilities,
                )
            };

            eprintln!("[TOOL EXECUTE] Original: {} → Actual: {}", request.tool_name, tool_name);

            // Execute tool based on (possibly translated) name
            let result = match tool_name.as_str() {
                "read_file" => {
                    // Extract file path from arguments
                    let path = tool_arguments.get("path")
                        .and_then(|v| v.as_str())
                        .unwrap_or("");

                    if path.is_empty() {
                        return Ok(Response::builder()
                            .status(StatusCode::BAD_REQUEST)
                            .header("content-type", "application/json")
                            .header("access-control-allow-origin", "*")
                            .body(Body::from(r#"{"error":"File path is required"}"#))
                            .unwrap());
                    }

                    // Read file
                    match fs::read_to_string(path) {
                        Ok(content) => {
                            serde_json::json!({
                                "success": true,
                                "result": content,
                                "path": path
                            })
                        }
                        Err(e) => {
                            serde_json::json!({
                                "success": false,
                                "error": format!("Failed to read file '{}': {}", path, e)
                            })
                        }
                    }
                }
                "write_file" => {
                    // Extract path and content from arguments
                    let path = tool_arguments.get("path")
                        .and_then(|v| v.as_str())
                        .unwrap_or("");
                    let content = tool_arguments.get("content")
                        .and_then(|v| v.as_str())
                        .unwrap_or("");

                    if path.is_empty() {
                        return Ok(Response::builder()
                            .status(StatusCode::BAD_REQUEST)
                            .header("content-type", "application/json")
                            .header("access-control-allow-origin", "*")
                            .body(Body::from(r#"{"error":"File path is required"}"#))
                            .unwrap());
                    }

                    // Write file
                    match fs::write(path, content) {
                        Ok(_) => {
                            serde_json::json!({
                                "success": true,
                                "result": format!("Successfully wrote {} bytes to '{}'", content.len(), path),
                                "path": path,
                                "bytes_written": content.len()
                            })
                        }
                        Err(e) => {
                            serde_json::json!({
                                "success": false,
                                "error": format!("Failed to write file '{}': {}", path, e)
                            })
                        }
                    }
                }
                "list_directory" => {
                    // Extract path and recursive flag from arguments
                    let path = tool_arguments.get("path")
                        .and_then(|v| v.as_str())
                        .unwrap_or(".");
                    let recursive = tool_arguments.get("recursive")
                        .and_then(|v| v.as_bool())
                        .unwrap_or(false);

                    // List directory contents
                    if recursive {
                        // Recursive listing using walkdir
                        use walkdir::WalkDir;
                        let entries: Vec<String> = WalkDir::new(path)
                            .into_iter()
                            .filter_map(|e| e.ok())
                            .map(|e| {
                                let metadata = e.metadata().ok();
                                let size = metadata.as_ref().and_then(|m| if m.is_file() { Some(m.len()) } else { None });
                                let file_type = if e.file_type().is_dir() { "DIR" } else { "FILE" };
                                format!("{:>10} {:>15} {}",
                                    file_type,
                                    size.map(|s| format!("{} bytes", s)).unwrap_or_else(|| "".to_string()),
                                    e.path().display()
                                )
                            })
                            .collect();

                        serde_json::json!({
                            "success": true,
                            "result": entries.join("\n"),
                            "path": path,
                            "count": entries.len(),
                            "recursive": true
                        })
                    } else {
                        // Non-recursive listing
                        match fs::read_dir(path) {
                            Ok(entries) => {
                                let items: Vec<String> = entries
                                    .filter_map(|e| e.ok())
                                    .map(|e| {
                                        let metadata = e.metadata().ok();
                                        let size = metadata.as_ref().and_then(|m| if m.is_file() { Some(m.len()) } else { None });
                                        let file_type = if metadata.as_ref().map(|m| m.is_dir()).unwrap_or(false) { "DIR" } else { "FILE" };
                                        format!("{:>10} {:>15} {}",
                                            file_type,
                                            size.map(|s| format!("{} bytes", s)).unwrap_or_else(|| "".to_string()),
                                            e.file_name().to_string_lossy()
                                        )
                                    })
                                    .collect();

                                serde_json::json!({
                                    "success": true,
                                    "result": items.join("\n"),
                                    "path": path,
                                    "count": items.len(),
                                    "recursive": false
                                })
                            }
                            Err(e) => {
                                serde_json::json!({
                                    "success": false,
                                    "error": format!("Failed to list directory '{}': {}", path, e)
                                })
                            }
                        }
                    }
                }
                "bash" | "shell" | "command" => {
                    // Extract command from arguments
                    let command = tool_arguments.get("command")
                        .and_then(|v| v.as_str())
                        .unwrap_or("");

                    if command.is_empty() {
                        return Ok(Response::builder()
                            .status(StatusCode::BAD_REQUEST)
                            .header("content-type", "application/json")
                            .header("access-control-allow-origin", "*")
                            .body(Body::from(r#"{"error":"Command is required"}"#))
                            .unwrap());
                    }

                    // Execute command (with timeout for safety)
                    let output = if cfg!(target_os = "windows") {
                        // Use PowerShell on Windows for better path and quoting handling
                        // PowerShell handles backslashes and quotes much better than cmd.exe
                        eprintln!("[BASH TOOL] Executing Windows command via PowerShell: {}", command);
                        std::process::Command::new("powershell")
                            .args(["-NoProfile", "-NonInteractive", "-Command", command])
                            .output()
                    } else {
                        eprintln!("[BASH TOOL] Executing Unix command: sh -c {}", command);
                        std::process::Command::new("sh")
                            .arg("-c")
                            .arg(command)
                            .output()
                    };

                    match output {
                        Ok(output) => {
                            let stdout = String::from_utf8_lossy(&output.stdout).to_string();
                            let stderr = String::from_utf8_lossy(&output.stderr).to_string();
                            let combined = if !stderr.is_empty() {
                                format!("{}\nSTDERR:\n{}", stdout, stderr)
                            } else {
                                stdout
                            };

                            serde_json::json!({
                                "success": true,
                                "result": combined,
                                "exit_code": output.status.code()
                            })
                        }
                        Err(e) => {
                            serde_json::json!({
                                "success": false,
                                "error": format!("Failed to execute command: {}", e)
                            })
                        }
                    }
                }
                _ => {
                    serde_json::json!({
                        "success": false,
                        "error": format!("Unknown tool: {}", request.tool_name)
                    })
                }
            };

            Response::builder()
                .status(StatusCode::OK)
                .header("content-type", "application/json")
                .header("access-control-allow-origin", "*")
                .body(Body::from(result.to_string()))
                .unwrap()
        }

        _ => {
            Response::builder()
                .status(StatusCode::NOT_FOUND)
                .body(Body::from("Not Found"))
                .unwrap()
        }
    };
    
    Ok(response)
}

#[tokio::main]
async fn main() -> std::io::Result<()> {
    // Create shared LLaMA state
    
    let llama_state: SharedLlamaState = Arc::new(Mutex::new(None));
    
    // Note: ConversationLogger will be created per chat request, not globally
    
    // Create HTTP service
    let make_svc = make_service_fn({
        
        let llama_state = llama_state.clone();
        
        move |_conn| {
            
            let llama_state = llama_state.clone();
            
            async move {
                Ok::<_, Infallible>(service_fn(move |req| {
                    
                    {
                        handle_request(req, llama_state.clone())
                    }
                    #[cfg(feature = "mock")]
                    {
                        handle_request(req)
                    }
                }))
            }
        }
    });
    
    // Start server
    let addr = SocketAddr::from(([0, 0, 0, 0], 8000));
    let server = Server::bind(&addr).serve(make_svc);
    
    println!("🦙 LLaMA Chat Web Server starting on http://{}", addr);
    println!("Available endpoints:");
    println!("  GET  /health               - Health check");
    println!("  POST /api/chat             - Chat with LLaMA");
    println!("  GET  /api/config           - Get sampler configuration");
    println!("  POST /api/config           - Update sampler configuration");
    println!("  GET  /api/model/status     - Get current model status");
    println!("  GET  /api/model/history    - Get model path history");
    println!("  POST /api/model/history    - Add model path to history");
    println!("  POST /api/model/load       - Load a specific model");
    println!("  POST /api/model/unload     - Unload current model");
    println!("  POST /api/upload           - Upload model file");
    println!("  GET  /api/conversations    - List conversation files");
    println!("  POST /api/tools/execute    - Execute tool calls");
    println!("  GET  /api/browse           - Browse model files");
    println!("  GET  /                     - Web interface");
    
    server.await.map_err(|e| std::io::Error::new(std::io::ErrorKind::Other, e))?;
    
    Ok(())
}